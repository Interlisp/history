/*  @(#) disp68K.il Version 2.17 (7/25/90). copyright envos & Fuji Xerox  *//* disp68K.il */ /* inline dispatching support *//* Bob Krivacic, Jan 6, 1988 *//* ************************************************************** * Changes:	'90/07/20 osamu: change _fvar_lookup_loop for Name table expand*****************************************************************/	***************************************************************	Fast inline dispatcher.	This routine is UNSAFE, since it assumes:		a5 = PC		d6 = 000000xx		a4 = @Table	****************************************************************/.inline	_fast0_dispatcher,0	movb	a5@(-1),d6	movl	a4@(0,d6:l:4),a0	.word	0x4ed0		|jmp	a0@	to clear up optimizer error	|.word	0x4ef4, 0x6d11	|jmp	[a4@(0,d6:l:4)] compiler will re-use d6	|jmp     a4@(0,d6:l:4)@ .end.inline	_fast1_dispatcher,0movb	a5@+,d6	movl	a4@(0,d6:l:4),a0	.word	0x4ed0		|jmp	a0@	to clear up optimizer error	|.word	0x4ef4, 0x6d11	|jmp	[a4@(0,d6:l:4)] compiler will re-use d6	|jmp     a4@(0,d6:l:4)@ .end.inline	_fast1_dispatcher2,0| The labels are to keep the optimizer from doing 2 a5@+'s| instead of the right thing on nextop2112$:	addql	#1,a5	movb	a5@+,d6	movl	a4@(0,d6:l:4),a0	.word	0x4ed0		|jmp	a0@	to clear up optimizer error	|.word	0x4ef4, 0x6d11	|jmp	[a4@(0,d6:l:4)] compiler will re-use d6	|jmp     a4@(0,d6:l:4)@ 	bcs	112$.end/*	***************************************************************	Inlines to produce ASM labels only, replaces asm("label:") in C	****************************************************************/.inline	_fixtos1_label,0fixtos1:.end.inline	_plus_err_label,0plus_err:.end.inline	_iplus_err_label,0iplus_err:.end.inline	_diff_err_label,0diff_err:.end.inline	_idiff_err_label,0idiff_err:.end.inline	_iplusn_err_label,0iplusn_err:.end.inline	_idiffn_err_label,0idiffn_err:.end.inline	_mpy_err_label,0mpy_err:.end.inline	_impy_err_label,0impy_err:.end.inline	_quot_err_label,0quot_err:.end.inline	_iquot_err_label,0iquot_err:.end.inline	_irem_err_label,0irem_err:.end.inline	_newframe_setup_label,0newframe_setup:	.globl	newframe_setup.end.inline	_newframe_loop_label,0newframe_loop:	.globl	newframe_loop.end.inline	_natnewframe_label,0natnewframe:.end/*	***************************************************************	Special Helper for Free Var Lookup.	****************************************************************/	/* **** assumes: 		d7 = name		d6 = i		a3 = pindex	*** */ /* NT expand version */.inline	_fvar_lookup_loop2,0lookup: 	cmpl a3@+,d7		dbeq d6,lookup		bne natnewframe.end/* Old NT(entry size 16bit) version */.inline	_fvar_lookup_loop,0lookup: 	cmpw a3@+,d7		dbeq d6,lookup		bne natnewframe.end/*	***************************************************************	Special Native Code Jump Routine.	****************************************************************/.inline	_asmgoto,4	movl	a7@+,a0	.word	0x4ed0		|jmp	a0@	to clear up optimizer error	movl	a0@,d0.end.inline	_asmgoto2,4	movl	a7@+,a0	.word	0x4ed0		|jmp	a0@	to clear up optimizer error.end.inline	_asmcall,4	movl	a7@+,a0	jsr	a0@.end.inline _setivar_pvar_jmp,12	movl	a7@+,a5		|set native IVAR	movl	a7@+,a4		|set native PVAR	movl	a7@+,a0		|get jump address	.word	0x4ed0		|jmp	a0@	to clear up optimizer error	movl	a0@,d0		|*** KEEP OPTIMIZER FROM REMOVING ABOVE CODE ***	movl	a4@,d1	movl	a5@,d2.end.inline _setpc_jmp,8	movl	a7@+,a5		|set the PCMAC	movl	a7@+,a0		|get the address	.word	0x4ed0		|jmp	a0@	to clear up optimizer error	movl	a0@,d0		|*** KEEP OPTIMIZER FROM REMOVING ABOVE CODE ***	movl	a5@,d1.end/*	***************************************************************	Routines to Fixup the C stack after an error return	from an Opcode Execution Routine.	****************************************************************/.inline	_fixra,4	movl	a7@+,a6@(4).end.inline	_fixsp1,0	addql	#4,a7.end.inline	_fixsp2,0	lea	a7@(8),a7.end.inline	_fixsp3,0	lea	a7@(12),a7.end.inline	_fixspn,4	movl	a7@+,d0	lea	a7@(0,d0:l:4),a7.end	/*	***************************************************************	Inlines to Decalare Labels	****************************************************************/.inline	_asm_label_op_fn_common,0op_fn_common:.end.inline	_asm_label_check_interrupt,0check_interrupt:.end/*	***************************************************************	Arithmetic Opcode Helpers	****************************************************************/.inline	_sub32,8	movl	a7@+,d0	movl	a7@+,d1	subl	d1,d0	bvs	diff_err.end.inline	_isub32,8	movl	a7@+,d0	movl	a7@+,d1	subl	d1,d0	bvs	idiff_err.end.inline	_sub32n,8	movl	a7@+,d0	movl	a7@+,d1	subl	d1,d0	bvs	idiffn_err.end.inline	_mpy32,8	movl	a7@+,d0	movl	a7@+,d1	mulsl	d1,d0	bvs	mpy_err.end.inline	_impy32,8	movl	a7@+,d0	movl	a7@+,d1	mulsl	d1,d0	bvs	impy_err.end.inline	_quot32,8	movl	a7@+,d0	movl	a7@+,d1	divsl	d1,d0	bvs	quot_err.end.inline	_iquot32,8	movl	a7@+,d0	movl	a7@+,d1	divsl	d1,d0	bvs	iquot_err.end.inline	_rem32,8	movl	a7@+,d2	movl	a7@+,d1	divsll	d1,d0:d2	bvs	rem_err.end.inline	_irem32,8	movl	a7@+,d2	movl	a7@+,d1	divsll	d1,d0:d2	bvs	irem_err.end.inline	_plus32,8	movl	a7@+,d0	movl	a7@+,d1	addl	d1,d0	bvs	plus_err.end.inline	_iplus32,8	movl	a7@+,d0	movl	a7@+,d1	addl	d1,d0	bvs	iplus_err.end.inline	_iplus32n,8	movl	a7@+,d0	movl	a7@+,d1	addl	d1,d0	bvs	iplusn_err.end/*	***************************************************************	Inline Assembly help for dispatcher.	****************************************************************//* Note: that the error exit of these routines may or may not need to	fix the tos pointer.  The C code should decide when tos must	be fixed through the ifdef flats.*//* SWAP halves of a register */.inline	_swapx,4	movl	a7@+,d0	swap	d0.end/*	***************************************************************	DIFFERENCE VERSIONS sp@ - sp@(4)  i.e. (tos-1)  -  (tos)	****************************************************************/.inline	_op_difference,8	movl	a7@+,d0	movl	a7@+,d1	moveq	#15,d2	roll	d2,d1	subqb	#7,d1	bne	diff_err	roll	d2,d0	subqb	#7,d0	bne	diff_err	subl	d1,d0	bvs	diff_err	lsrl	d2,d0	orl	#0x000E0000,d0.end.inline	_fast_op_difference,4	movl	a7@+,d1	roll	d5,d7	subqb	#7,d7	bne	diff_err	roll	d5,d1	subqb	#7,d1	bne	diff_err	subl	d7,d1	bvs	diff_err	lsrl	d5,d1	orl	#0x000E0000,d1	movl	d1,d7.end.inline	_fast_op_idifference,4	movl	a7@+,d1	roll	d5,d7	subqb	#7,d7	bne	idiff_err	roll	d5,d1	subqb	#7,d1	bne	idiff_err	subl	d7,d1	bvs	idiff_err	lsrl	d5,d1	orl	#0x000E0000,d1	movl	d1,d7.end.inline	_fast_op_idifferencen,4	movl	a7@+,d0	roll	d5,d0	roll	d5,d7	subqb	#7,d7	bne	idiffn_err	subl	d0,d7	bvs	idiffn_err	lsrl	d5,d7	orl	#0x000E0000,d7.end/*	***************************************************************	PLUS VERSIONS sp@ + sp@(4)  i.e. (tos-1)  +  (tos)	****************************************************************/.inline	_op_plus,8	movl	a7@+,d0	movl	a7@+,d1	moveq	#15,d2	roll	d2,d1	subqb	#7,d1	bne	plus_err	roll	d2,d0	subqb	#7,d0	bne	plus_err	addl	d1,d0	bvs	plus_err	lsrl	d2,d0	orl	#0x000E0000,d0.end.inline	_fast_op_plus,4	movl	a7@+,d0	roll	d5,d7	subqb	#7,d7	bne	plus_err	roll	d5,d0	subqb	#7,d0	bne	plus_err	addl	d7,d0	bvs	plus_err	lsrl	d5,d0	movl	d0,d7	orl	#0x000E0000,d7.end.inline	_fast_op_iplus,4	movl	a7@+,d0	roll	d5,d7	subqb	#7,d7	bne	iplus_err	roll	d5,d0	subqb	#7,d0	bne	iplus_err	addl	d7,d0	bvs	iplus_err	lsrl	d5,d0	movl	d0,d7	orl	#0x000E0000,d7.end.inline	_fast_op_iplusn,4	movl	a7@+,d0	roll	d5,d0	roll	d5,d7	subqb	#7,d7	bne	iplusn_err	addl	d0,d7	bvs	iplusn_err	lsrl	d5,d7	orl	#0x000E0000,d7.end/*	***************************************************************	LOGAND VERSIONS sp@ & sp@(4)  i.e. (tos-1)  &  (tos)	****************************************************************/.inline	_op_logand,8	movl	a7@+,d0	movl	a7@+,d1	moveq	#15,d2	moveq	#7,d3	roll	d2,d1	cmpb	d3,d1	bne	logand_err	roll	d2,d0	cmpb	d3,d0	bne	logand_err	andl	d1,d0	rorl	d2,d0.end.inline	_fast_op_logand,4	movl	a7@+,d0	roll	d5,d7	cmpb	#7,d7	bne	logand_err	roll	d5,d0	cmpb	#7,d0	bne	logand_err	andl	d0,d7	rorl	d5,d7.end/*	***************************************************************	LOGOR VERSIONS sp@ | sp@(4)  i.e. (tos-1)  |  (tos)	****************************************************************/.inline	_op_logor,8	movl	a7@+,d0	movl	a7@+,d1	moveq	#15,d2	moveq	#7,d3	roll	d2,d1	cmpb	d3,d1	bne	logor_err	roll	d2,d0	cmpb	d3,d0	bne	logor_err	orl	d1,d0	rorl	d2,d0.end.inline	_fast_op_logor,4	movl	a7@+,d0	roll	d5,d7	cmpb	#7,d7	bne	logor_err	roll	d5,d0	cmpb	#7,d0	bne	logor_err	orl	d0,d7	rorl	d5,d7.end/*	***************************************************************	LOGXOR VERSIONS sp@ | sp@(4)  i.e. (tos-1)  |  (tos)	****************************************************************/.inline	_op_logxor,8	movl	a7@+,d0	movl	a7@+,d1	moveq	#15,d2	moveq	#7,d3	roll	d2,d1	subb	d3,d1	bne	logxor_err	roll	d2,d0	cmpb	d3,d0	bne	logxor_err	eorl	d1,d0	rorl	d2,d0.end.inline	_fast_op_logxor,4	movl	a7@+,d0	roll	d5,d7	cmpb	#7,d7	bne	logxor_err	roll	d5,d0	subqb	#7,d0	bne	logxor_err	eorl	d0,d7	rorl	d5,d7.end/*	***************************************************************	SHIFT OPCODE VERSIONS	****************************************************************/.inline	_op_lrsh8,4	movl	a7@+,d0	moveq	#15,d2	movl	d0,d1	swap	d1	cmpw	#0xe,d1	bne	lrsh8_err	lsrw	#8,d0.end.inline	_fast_op_lrsh8,0	movl	d7,d1	swap	d1	cmpw	#0xe,d1	bne	lrsh8_err	lsrw	#8,d7.end/* inline LRSH1 *//* 	sp@ >> 1*/.inline	_op_lrsh1,4	movl	a7@+,d0	moveq	#15,d2	movl	d0,d1	swap	d1	cmpw	#0xe,d1	bne	lrsh1_err	lsrw	#1,d0.end.inline	_fast_op_lrsh1,0	movl	d7,d1	swap	d1	cmpw	#0xe,d1	bne	lrsh1_err	lsrw	#1,d7.end.inline	_op_llsh8,4	movl	a7@+,d0	cmpw	#0x0FF,d0	bhi	llsh8_err	movl	d0,d1	swap	d1	cmpw	#0xe,d1	bne	llsh8_err	lslw	#8,d0.end.inline	_fast_op_llsh8,0	cmpw	#0x0FF,d7	bhi	llsh8_err	movl	d7,d1	swap	d1	cmpw	#0xe,d1	bne	llsh8_err	lslw	#8,d7.end.inline	_op_llsh1,4	movl	a7@+,d0	cmpw	#0x07FFF,d0	bhi	llsh1_err	movl	d0,d1	swap	d1	cmpw	#0xe,d1	bne	llsh1_err	lslw	#1,d0.end.inline	_fast_op_llsh1,0	cmpw	#0x07FFF,d7	bhi	llsh1_err	movl	d7,d1	swap	d1	cmpw	#0xe,d1	bne	llsh1_err	lslw	#1,d7.end/*	***************************************************************	GREATERP OPCODE VERSIONS	****************************************************************/.inline	_op_greaterp,8	movl	a7@+,d3	movl	a7@+,d1	moveq	#15,d2	roll	d2,d1	subqb	#7,d1	bne	greaterp_err	roll	d2,d3	subqb	#7,d3	bne	greaterp_err	clrl	d0	cmpl	d1,d3	ble	100$	moveq	#76,d0100$:.end.inline	_fast_op_greaterp,4	movl	a7@+,d1	movl	d7,d3	roll	d5,d3	subqb	#7,d3	bne	greaterp_err	roll	d5,d1	subqb	#7,d1	bne	greaterp_err	clrl	d7	cmpl	d3,d1	ble	100$	moveq	#76,d7100$:.end.inline	_fast_op_igreaterp,4	movl	a7@+,d1	movl	d7,d3	roll	d5,d3	subqb	#7,d3	bne	igreaterp_err	roll	d5,d1	subqb	#7,d1	bne	igreaterp_err	clrl	d7	cmpl	d3,d1	ble	101$	moveq	#76,d7101$:.end/*	***************************************************************	POINTER OPCODE VERSIONS	****************************************************************/.inline _addbase,8	movl	a7@+,d0	movl	a7@+,d1	moveq	#15,d2	roll	d2,d1	subqb	#7,d1	bne	fixtos1	asrl	d2,d1	andl	#0xFFFFFF,d0	addl	d1,d0.end.inline _fast_op_addbase,4	movl	a7@+,d0	roll	d5,d7	subqb	#7,d7	bne	addbase_err	asrl	d5,d7	andl	#0xFFFFFF,d0	addl	d0,d7.end.inline _loloc,4	movl	a7@+,d0|	commented code is messed up by the optimizer (movw -> moveq)|	swap	d0|	movw	#0x000E,d0|	swap	d0	andl	#0x0000FFFF,d0	orl	#0x000E0000,d0.end.inline _fast_op_loloc,0	andl	#0x0000FFFF,d7	orl	#0x000E0000,d7.end.inline	_hiloc,4	movl	a7@+,d0|	commented code is messed up by the optimizer (movw -> moveq)|	movw	#0x000E,d0|	swap	d0|	andw	#0x00FF,d0	swap	d0	andl	#0x0000FFFF,d0	orl	#0x000E0000,d0.end.inline	_fast_op_hiloc,0	swap	d7	andl	#0x0000FFFF,d7	orl	#0x000E0000,d7.end/* this really doesn't need to check */.inline	_vag2,8	movl	a7@+,d0	movl	a7@+,d1	swap	d0	swap	d1	cmpb	#0x0E,d0	bne	fixtos1	cmpb	#0x0E,d1	bne	fixtos1	swap	d1	movw	d1,d0.end.inline	_fast_op_vag2,4	movl	a7@+,d0	swap	d7	movw	d0,d7	swap	d7.end	/*	***************************************************************	TYPE OPCODE VERSIONS	****************************************************************//* TYPE INLINE OPCODES */.inline	_listp,4	movl	a7@+,d0	movl	d0,d1	lsrl	#8,d1	andl	#0xFFFE,d1	movl	_MDStypetbl,a0	movw	a0@(0,d1:l:1),d1	andw	#0x7FF,d1	cmpw	#5,d1	jeq	110$	clrl	d0110$:.end.inline	_fast_op_listp,0	movl	d7,d1	lsrl	#8,d1	andl	#0xFFFE,d1	movl	_MDStypetbl,a0	movw	a0@(0,d1:l:1),d1	andw	#0x7FF,d1	cmpw	#5,d1	jeq	110$	clrl	d7110$:.end.inline	_ntypex,4	movl	a7@+,d1	lsrl	#8,d1	andl	#0xFFFE,d1	movl	_MDStypetbl,a0	movl	#0x000E0000,d0	movw	a0@(0,d1:l:1),d0	andw	#0x7FF,d0.end.inline	_fast_op_ntypex,0	lsrl	#8,d7	andl	#0xFFFE,d7	movl	_MDStypetbl,a0	movw	a0@(0,d7:l:1),d7	andw	#0x7FF,d0	orl	#0x000E0000,d7.end.inline _typep,8	movl	a7@+,d1	movl	a7@+,d2	movl	d1,d0	lsrl	#8,d1	andl	#0xFFFE,d1	movl	_MDStypetbl,a0	movw	a0@(0,d1:l:1),d1	andw	#0x7FF,d1	cmpl	d2,d1	beq	115$	moveq	#0,d0115$:.end.inline _fast_op_typep,0	movl	d7,d0	lsrl	#8,d0	andl	#0xFFFE,d0	movl	_MDStypetbl,a0	movw	a0@(0,d0:l:1),d0	andw	#0x7FF,d0	moveq	#0,d1	movb	a5@,d1	cmpw	d1,d0	beq	115$	moveq	#0,d7115$:.end/* TYPE INLINE FUNCTIONS */.inline _GetTypeNumber,4	movl	a7@+,d1	asrl	#8,d1	andl	#0xFFFE,d1	movl	_MDStypetbl,a0	moveq	#00,d0	movw	a0@(0,d1:l:1),d0	andw	#0x7FF,d0.end.inline _GetTypeEntry,4	movl	a7@+,d1	asrl	#8,d1	andl	#0xFFFE,d1	movl	_MDStypetbl,a0	movw	a0@(0,d1:l:1),d0.end	/*	***************************************************************	Code for RETURN opcode	****************************************************************/.inline	_opreturn,0	movl	_MachineState+4,a2		|a2 = PVAR	moveq	#0,d3	movw	a2@(-18),d3			|d3 = FX >> 1	lsrl	#1,d3	jcs	do_slow_return			|jump if must do slow return	movl	_MachineState,a3	movl	_Stackspace,a1			|a1 = Stackspace	lea	a1@(0,d3:w:4),a2		|a2 = new PVAR	movl	a2,_MachineState+4	moveq	#0,d0	movw	a2@(-22),d0			|*(returnFX -1)	lea	a1@(0,d0:l:2),a0	movl	a0,_MachineState		|IVAR = 	movl	a2@(-16),d0			|returnFX->fnheader	swap	d0	andl	#16777215,d0				movl	_Lisp_world,a5	lea	a5@(0,d0:l:2),a0		|Addr68k_from_LADDR	movl	a0,_MachineState+20		|FuncObj = 	moveq	#0,d4				|returnFX->pc	movw	a2@(-10),d4	lea	a0@(0,d4:l:1),a5		|PCMAC = 	moveq	#0,d0	movw	a0@,d0				|stkmin	lsll	#1,d0	movl	_MachineState+24,d1		|_EndSTKP	movl	d1,d2				|d2 = save _EndSTKP	subl	d0,d1	movl	d1,_MachineState+28 		|_Irq_Stk_Check	cmpl	d1,a3	jgt	do_a_timer_check	tstl	_MachineState+32 		|_Irq_Stk_End	jle	do_a_timer_check	movl	d2,_MachineState+32		|_Irq_Stk_End = _EndSTKP  	btst	#3,a2@(-20)			|test native bit	jne	is_native_return		|jump if a native returndo_a_dispatch:	movb	a5@+,d6				|dispatch	movl	a4@(0,d6:l:4),a0	.word	20176is_native_return:						|a0 is still _FuncObj						|d4 = returnFX->pc	moveq	#0,d0	movw	a0@(6),d0			|startpc	movl	a0@(-4,d0:l:1),a1		|*(fnobj + startpc - 40)	movl	a1@(32,d4:l:4),a0		|get entry addr	movl	a0,d3				|test it	jeq	do_a_dispatch			|no entry point	movl	d7,a3@+				|push TOPOFSTACK	movl	_MachineState+4,a4		|setup PVAR	movl	_MachineState,a5		|setup IVAR	.word	20176	movl	a0@,d0	movl	a4@,d1	movl	a5@,d2do_a_timer_check:	movl	#256,d6	addql	#1,a5			|bump PCMAC past current position	jmp	check_interruptdo_slow_return:.end/*	***************************************************************	COMPONENTS OF FN CALL	****************************************************************//*	Head Section of code	*/.inline _fnx_section1,0	moveq	#0,d1			|# args	movb	a5@,d1			|carefull this gets zapped!	moveq	#0,d0			|Get Atom Index	movw	a5@(1),d0	movl	_Defspace,a0		|Turn into Addr of Def Cell	movl	a0@(0,d0:l:4),d4	|d4 = defcell word	jge	400$			|Jump if not CCodeP	andl	#16777215,d4		movl	_Lisp_world,a2	lea	a2@(0,d4:l:2),a2	|a2 = LOCFNCELL	movl	_MachineState+4,a1	|a1 = PVAR	lea	a5@(3),a0		|BCE_CURRENTFX->pc	.end.inline _fn_section1,0	moveq	#0,d0			|Get Atom Index	movw	a5@,d0	movl	_Defspace,a0		|Turn into Addr of Def Cell	movl	a0@(0,d0:l:4),d4	|d4 = defcell word	jge	400$			|Jump if not CCodeP	andl	#16777215,d4		movl	_Lisp_world,a2	lea	a2@(0,d4:l:2),a2	|a2 = LOCFNCELL	movl	_MachineState+4,a1	|a1 = PVAR	lea	a5@(2),a0		|BCE_CURRENTFX->pc	.end.inline _fn_section2,0	subl	_MachineState+20,a0	|PCMAC - FuncObj	movw	a0,a1@(-10).end.inline _fn0_args,0	lea	a3@(4),a0		|a0 = newivar = CSTKPTR - x + 1.end.inline _fn1_args,0	lea	a3@(0),a0		|a0 = newivar = CSTKPTR - x + 1.end.inline _fn2_args,0	lea	a3@(-4),a0		|a0 = newivar = CSTKPTR - x + 1.end.inline _fn3_args,0	lea	a3@(-8),a0		|a0 = newivar = CSTKPTR - x + 1.end.inline _fn4_args,0	lea	a3@(-12),a0		|a0 = newivar = CSTKPTR - x + 1.end.inline _fnx_args,0	negl	d1	lea	a3@(4,d1:l:4),a0	|a0 = newivar = CSTKPTR - x + 1.end.inline _fn_native_test,0	movl	a2@(8),d0		|get flags from FN header	jmi	450$			|jump if a native call.end.inline _fn_section3,0	moveq	#0,d0			|d0 = stkmin	movw	a2@,d0	lsll	#1,d0	movl	_MachineState+32,d2	|_Irq_Stk_End	subl	d0,d2			|end - min	movl	d2,_MachineState+28	|Irq_Stk_Check = end - min	cmpl	d2,a3			|CSTKPTR > Irq_Stk_Check	jgt	check_interrupt		|jump if stack overflow	movl	a0,_MachineState	movl	_Stackspace,d2		|d2 = Stackspace	subl	d2,a0	movl	a0,d3			|d3 = NEXTBLOCK	lsrl	#1,d3	movw	d3,a1@(-12)		|BCE_CURRENTFX->nextblock =	movl	d7,a3@+	movw	a2@(2),d0		|LOCFNCELL->na	jlt	275$			|jump if no need to loop	extl	d0.end.inline _fn0_xna,0	moveq	#0,d1			|x - na.end.inline _fn1_xna,0	moveq	#1,d1			|x - na.end.inline _fn2_xna,0	moveq	#2,d1			|x - na.end.inline _fn3_xna,0	moveq	#3,d1			|x - na.end.inline _fn4_xna,0	moveq	#4,d1			|x - na.end.inline _fnx_xna,0	negl	d1			|x - na.end.inline _fn_section4,0	subl	d0,d1	jpl	250$200$:	clrl	a3@+	addql	#1,d1	jmi	200$250$:	asll	#2,d1	subl	d1,a3275$:	orl	#-2147483648,d3	movl	d3,a3@+	movl	a1,d0			|(StkOffset_from_68K(PVAR)	subl	d2,d0	lsrl	#1,d0	orl	#-1073741824,d0		|(FX_MARK << 16)	movl	d0,a3@	swap	d4			|SWAP_WORDS(defcell_word)	movl	d4,a3@(4)	lea	a3@(20),a3		|CSTKPTR += FRAMESIZE	movl	a3,_MachineState+4	|PVAR = (LispPTR *) CSTKPTR	movw	a2@(4),d2		|result = LOCFNCELL->pv	extl	d2	jlt	350$	moveq	#-1,d4325$:	movl	d4,a3@+	movl	d4,a3@+	dbra	d2,325$350$:	addqw	#4,a3	moveq	#0,d0	movw	a2@(6),d0	lea	a2@(0,d0:l),a5	movl	a2,_MachineState+20	|_FuncObj.end.inline _fn0_native,0450$:	movl	a0,a5			|Set the IVAR (NEED x)	movl	a2,_MachineState+20	|_FuncObj	movl	d7,a3@+	moveq	#0,d0	movw	a2@(6),d0	movl	d0,a0	movl	a0@(-4,a2:l),a0	movl	a0@(32),a0		|Set entry address	movl	a1,a4			|Set native PVAR	.word	20176			|Jump to native code	movl	a0@,d0	movl	a4@,d1	movl	a5@,d2.end.inline _fn1_native,0450$:	movl	a0,a5			|Set the IVAR (NEED x)	movl	a2,_MachineState+20	|_FuncObj	movl	d7,a3@+	moveq	#0,d0	movw	a2@(6),d0	movl	d0,a0	movl	a0@(-4,a2:l),a0	movl	a0@(28),a0		|Set entry address	movl	a1,a4			|Set native PVAR	.word	20176			|Jump to native code	movl	a0@,d0	movl	a4@,d1	movl	a5@,d2.end.inline _fn2_native,0450$:	movl	a0,a5			|Set the IVAR (NEED x)	movl	a2,_MachineState+20	|_FuncObj	movl	d7,a3@+	moveq	#0,d0	movw	a2@(6),d0	movl	d0,a0	movl	a0@(-4,a2:l),a0	movl	a0@(24),a0		|Set entry address	movl	a1,a4			|Set native PVAR	.word	20176			|Jump to native code	movl	a0@,d0	movl	a4@,d1	movl	a5@,d2.end.inline _fn3_native,0450$:	movl	a0,a5			|Set the IVAR (NEED x)	movl	a2,_MachineState+20 	|_FuncObj	movl	d7,a3@+	moveq	#0,d0	movw	a2@(6),d0	movl	d0,a0	movl	a0@(-4,a2:l),a0	movl	a0@(20),a0		|Set entry address	movl	a1,a4			|Set native PVAR	.word	20176			|Jump to native code	movl	a0@,d0	movl	a4@,d1	movl	a5@,d2.end.inline _fn4_native,0450$:	movl	a0,a5			|Set the IVAR (NEED x)	movl	a2,_MachineState+20 	|_FuncObj	movl	d7,a3@+	moveq	#0,d0	movw	a2@(6),d0	movl	d0,a0	movl	a0@(-4,a2:l),a0	movl	a0@(16),a0		|Set entry address	movl	a1,a4			|Set native PVAR	.word	20176			|Jump to native code	movl	a0@,d0	movl	a4@,d1	movl	a5@,d2.end.inline _fnx_native,0450$:	movl	a0,a5			|Set the IVAR (NEED x)	movl	a2,_MachineState+20 	|_FuncObj	movl	d7,a3@+	moveq	#0,d0	movw	a2@(6),d0	movl	d0,a0	movl	a0@(-4,a2:l),a0	movl	a1,a4			|Set native PVAR	movl	d1,_MachineState+16	|set the PC for the entry loop	addql	#5,d1			|see if less than 6 args	bpl	455$			|go do indexed jump if so	movl	a0@(8),a0		|fnx(6) call	.word	20176			|Jump to native code	movl	a5@,d2	movl	a0@,d0	movl	a4@,d1455$:	movl	a0@(12,d1:l:4),a0	|Set entry address	.word	20176			|Jump to native code	movl	a4@,d1	movl	a0@,d0	movl	a5@,d2.end.inline _fn_section5,0400$:			|following "C" code does setup to opfn common			|.end/*	***************************************************************	CODE TO HELP FREE VARIABLE LOOKUP	****************************************************************/.inline	_newframe_stk_hi_ret,4|	STK_HI is 1|	result returned in d0	movl	a7@+,d0	swap	d0	moveq	#1,d1	orl	d1,d0		|or in the STK_HI to lower word.end.inline	_newframe_vals_hi_ret,4|	VALS_HI is 12|	result returned in d0	movl	a7@+,d0	moveq	#17,d1		|need to get shift amount	roll	d1,d0		|shift the 1st bit of name to lsb	orw	#12,d0		|or in the VALS_HI to lower word.end/*	***************************************************************	NATIVE CODE INLINE ASSEMBLY CODE	***************************************************************		Assume:		d5 = 15		Shift Amount*//*	****************************************************************//*	Boxing & Unboxing					       *//*	****************************************************************/.inline _nop_nsmallp_range,4	movl	a7@,d0	movl	d0,d1		|save value	lsll	d5,d0		|x = value << 15	asrl	d5,d0		|x = x >> 15	eorl	d1,d0		|x = x EOR value.end.inline _nop_smallp_unbox,4	movl	a7@,d0	lsll	d5,d0		|x = value << 15	asrl	d5,d0		|x = x >> 15.end	.inline _nop_smallp_box,4	movl	a7@,d0	lsll	d5,d0		|x = value << 15	lsrl	d5,d0		|x = x >> 15	orl	#0x000e0000,d0.end	/*	****************************************************************//*	UNBIND & DUNBIND					       *//*	****************************************************************/.inline _nop_unbind,4|| Assumes: 	a3 = CURRSTKP|		a4 = PVAR|	movl	a7@+,a1		|save TOS value10$:	tstl	a3@-		|look for bind mark	bpls	10$	movl	a3@,d0		|get the bind mark	movl	d0,d1		|get num of pvars to unbind	movl	#0xffff,d2	andl	d2,d0		|get pvar index	lea	a4@(4,d0:l:2),a0	swap	d1		|compute num of pvars to unbind	notw	d1	andl	d2,d1		|clear top of num	beqs	30$		|jump if none to clear	subql	#1,d1		|adjust counter for loop	moveq	#-1,d0		|set loop store value20$:	movl	d0,a0@-		|Store the unbind mark in pvars	dbra	d1,20$		|loop till pvars cleared30$:	movl	a1,a3@+		|push the old TOS.end.inline _nop_dunbind,0|| Assumes: 	a3 = CURRSTKP|		a4 = PVAR|10$:	tstl	a3@-		|look for bind mark	bpls	10$	movl	a3@,d0		|get the bind mark	movl	d0,d1		|get num of pvars to unbind	movl	#0xffff,d2	andl	d2,d0		|get pvar index	lea	a4@(4,d0:l:2),a0	swap	d1		|compute num of pvars to unbind	notw	d1	andl	d2,d1		|clear top of num	beqs	30$		|jump if none to clear	subql	#1,d1		|adjust counter for loop	moveq	#-1,d0		|set loop store value20$:	movl	d0,a0@-		|Store the unbind mark	dbra	d1,20$		|loop till pvars cleared30$:	.end/************************************************************************//*									*//*		    _ s x h a s h _ r o t a t e				*//*									*//*	Rotate the low word of its argument to the right by 7 bits	*//*	This is equivalent to the SXHASH-ROTATE macro in CMLHASH.	*//*									*//************************************************************************/.inline _sxhash_rotate,4| Rotates the low word to the right by 7 bits.| This is the equivalent of the SXHASH-ROTATE macro in CMLHASH.|	movl	a7@+,d0	rolw	#7,d0.end/************************************************************************//*									*//*									*//*									*//*									*//************************************************************************/|.inline _min,8|	movl	a7@+,d0|	movl	a7@+,d1|	cmpl	d1,d0|	jge	$30|	movl	d1,d0|$30|.end|.inline _max,8|	movl	a7@+,d0|	movl	a7@+,d1|	cmpl	d1,d0|	jle	$30|	movl	d1,d0|$30|.end